import feedparser
import json
import os
from datetime import datetime

# ==========================================
# [Ver 0.1.1] ê¸€ë¡œë²Œ ì •ì˜ˆ ë‰´ìŠ¤ ì†ŒìŠ¤ (êµ­ë‚´ ë§¤ì²´ ë°°ì œ)
# ==========================================
RSS_FEEDS = {
    # ë¯¸êµ­/ê¸€ë¡œë²Œ (í•µì‹¬ ë§¤í¬ë¡œ ì†ŒìŠ¤)
    "Bloomberg_Markets": "https://www.bloomberg.com/feeds/bview/main.rss",
    "NYTimes_Business": "https://rss.nytimes.com/services/xml/rss/nt/Business.xml",
    "CNN_Business": "http://rss.cnn.com/rss/money_latest.rss",
    "Reuters_Finance": "https://www.reutersagency.com/feed/?best-sectors=business-finance&post_type=best",
    "GoogleNews_Global": "https://news.google.com/rss/search?q=global+economy+stock+market&hl=en-US&gl=US&ceid=US:en",
    
    # ì•„ì‹œì•„/ì‹ í¥êµ­ (ì§€ì—­ë³„ ì˜í–¥ë ¥ ë§¤ì²´)
    "Nikkei_Asia_Japan": "https://asia.nikkei.com/rss/feed/nar",
    "CCTV_English_China": "https://english.cctv.com/data/rss/index.xml",
    "NDTV_Profit_India": "https://feeds.feedburner.com/ndtvprofit-latest",
    "Antara_Indonesia": "https://en.antaranews.com/rss/business.xml"
}

def collect_pure_global_news():
    print(f"ğŸŒ [GlobalStockNow Ver 0.1.1] ê¸€ë¡œë²Œ ìˆ˜ì§‘ ê°€ë™: {datetime.now()}")
    all_articles = []

    for source_name, url in RSS_FEEDS.items():
        try:
            print(f"   ğŸ“¡ Connecting to {source_name}...")
            feed = feedparser.parse(url)
            
            # ê° ì†ŒìŠ¤ë³„ ìµœì‹  10ê°œ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
            for entry in feed.entries[:10]:
                # [ë³´ìŠ¤ ì§€ì¹¨ ë°˜ì˜] í‚¤ì›Œë“œ í•„í„°ë§ì„ í•˜ì§€ ì•Šê³  ëª¨ë“  ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
                # ì´ë¥¼ í†µí•´ ì „ìŸ, ë‚©ì¹˜ ë“± í•µì‹¬ ë§¤í¬ë¡œ ë‰´ìŠ¤ì˜ ëˆ„ë½ì„ ë°©ì§€í•©ë‹ˆë‹¤.
                
                article = {
                    "source": source_name,
                    "title": entry.get('title', ''),
                    "link": entry.get('link', ''),
                    "published_at": entry.get('published', ''),
                    "summary": entry.get('summary', '')[:500] # ë¶„ì„ìš© í…ìŠ¤íŠ¸ í™•ë³´
                }
                all_articles.append(article)
        except Exception as e:
            print(f"   âŒ {source_name} ì—°ê²° ì‹¤íŒ¨: {e}")

    # ìˆ˜ì§‘ ê²°ê³¼ ì €ì¥ (ë¶„ì„ê¸°ê°€ ì½ì„ íŒŒì¼)
    output = {
        "collected_at": str(datetime.now()),
        "count": len(all_articles),
        "articles": all_articles
    }
    
    with open('breaking_news.json', 'w', encoding='utf-8') as f:
        json.dump(output, f, ensure_ascii=False, indent=4)
    
    print(f"âœ… ìˆ˜ì§‘ ì™„ë£Œ: ì´ {len(all_articles)}ê±´ì˜ ê¸€ë¡œë²Œ ë‰´ìŠ¤ í™•ë³´.")

if __name__ == "__main__":
    collect_pure_global_news()
