"""Module: collector.py | Version: 0.1.5 | Updated: 2026-01-11"""
import feedparser, json, os, urllib.parse
from datetime import datetime, timedelta, timezone
from dateutil import parser # ë‚ ì§œ íŒŒì‹± ë¼ì´ë¸ŒëŸ¬ë¦¬ í™œìš©

Q_DEF = urllib.parse.quote('KF-21 OR "Nuclear Submarine" OR "K-Defense" OR "North Korea"')
Q_TEC = urllib.parse.quote('Apple OR Meta OR "Nuclear Power" OR "AI Data Center"')

RSS_FEEDS = {
    "GNews_Defense": f"https://news.google.com/rss/search?q={Q_DEF}&hl=en-US&gl=US&ceid=US:en",
    "GNews_BigTech": f"https://news.google.com/rss/search?q={Q_TEC}&hl=en-US&gl=US&ceid=US:en",
    "Bloomberg": "https://www.bloomberg.com/feeds/bview/main.rss"
}

def collect():
    print("ğŸŒ [Ver 0.1.5] 48ì‹œê°„ ì´ë‚´ ì†ë³´ë§Œ ì—„ì„  ìˆ˜ì§‘ ì¤‘...")
    all_articles = []
    # [í•µì‹¬] ìˆ˜ì§‘ ê¸°ì¤€ ì‹œê°„ ì„¤ì •: í˜„ì¬ë¶€í„° 48ì‹œê°„ ì „
    now = datetime.now(timezone.utc)
    limit = now - timedelta(hours=48)

    for name, url in RSS_FEEDS.items():
        try:
            feed = feedparser.parse(url)
            for entry in feed.entries[:15]:
                pub_at = entry.get('published', '')
                try:
                    # ë‚ ì§œ íŒŒì‹± ë° íƒ€ì„ì¡´ ë³´ì •
                    pub_date = parser.parse(pub_at)
                    if pub_date.tzinfo is None: pub_date = pub_date.replace(tzinfo=timezone.utc)
                    
                    # [í•„í„° ì ìš©] 48ì‹œê°„ ì´ë‚´ ê¸°ì‚¬ë§Œ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
                    if pub_date >= limit:
                        all_articles.append({
                            "source": name,
                            "title": entry.get('title', ''),
                            "link": entry.get('link', ''),
                            "published_at": pub_at,
                            "summary": entry.get('summary', '')[:500]
                        })
                except: continue
        except: pass
    
    with open('breaking_news.json', 'w', encoding='utf-8') as f:
        json.dump({"collected_at": str(now), "articles": all_articles}, f, ensure_ascii=False, indent=4)
    print(f"âœ… í•„í„°ë§ ì™„ë£Œ: ì´ {len(all_articles)}ê±´ì˜ ì†ë³´ ì €ì¥.")

if __name__ == "__main__": collect()
