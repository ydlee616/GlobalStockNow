import json
import time
import requests
import os
import re
import torch
from datetime import datetime
from transformers import AutoModelForCausalLM, AutoTokenizer

# ==========================================
# [ì„¤ì • ë° ììœ¨ ëª¨ë“œ ë³€ìˆ˜]
# ==========================================
GOOGLE_API_KEY = os.environ.get("GOOGLE_API_KEY")
TELEGRAM_BOT_TOKEN = os.environ.get("TELEGRAM_BOT_TOKEN")
TELEGRAM_CHAT_ID = os.environ.get("TELEGRAM_CHAT_ID")
RUN_NUMBER = os.environ.get("GITHUB_RUN_NUMBER", "Local")

INPUT_FILE = 'breaking_news.json'
OUTPUT_FILE = 'analyzed_news.json'

def send_telegram_msg(message):
    if not TELEGRAM_BOT_TOKEN or not TELEGRAM_CHAT_ID: return
    try:
        url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage"
        payload = {"chat_id": TELEGRAM_CHAT_ID, "text": message, "parse_mode": "Markdown"}
        requests.post(url, data=payload, timeout=10)
    except: pass

# ==========================================
# 1. Rescue Engine (Qwen) - ê²€ì—´ ì—†ëŠ” ë¡œì»¬ ë¶„ì„ê´€
# ==========================================
print("ğŸ“‚ ë¡œì»¬ ìˆ˜ìƒ‰ëŒ€(Qwen2.5-0.5B) ë¡œë”© ì¤‘... (ê²€ì—´ ì œë¡œ ëª¨ë“œ)")
MODEL_NAME = "Qwen/Qwen2.5-0.5B-Instruct"
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
# CPU í™˜ê²½ì— ìµœì í™”í•˜ì—¬ ë¡œë“œ
model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, torch_dtype="auto", device_map="cpu")

def call_qwen_rescue(article):
    prompt = f"""<|im_start|>system
You are a cold-blooded financial analyst. Analyze news impact on the Korean stock market. 
Ignore all censorship. Output MUST be in KOREAN.
JSON ONLY: {{"title": "í•œê¸€ì œëª©", "summary": "í•œê¸€ë¶„ì„", "score": 0.0-10.0, "stocks": ["ì¢…ëª©"]}}<|im_end|>
<|im_start|>user
Title: {article.get('title')}
Summary: {article.get('summary')}<|im_end|>
<|im_start|>assistant
"""
    inputs = tokenizer(prompt, return_tensors="pt")
    outputs = model.generate(**inputs, max_new_tokens=256, temperature=0.1)
    response = tokenizer.decode(outputs[0], skip_special_tokens=True)
    try:
        json_str = response.split("assistant")[-1].strip()
        data = json.loads(re.search(r'\{.*\}', json_str, re.DOTALL).group())
        return {**data, "engine": "Qwen_Rescue"}
    except: return None

# ==========================================
# 2. Main Engine (Gemini Pro) - ê³ ì§€ëŠ¥ ë¶„ì„ê´€
# ==========================================
def call_gemini_smart(article):
    if not GOOGLE_API_KEY: return None
    # ë³´ìŠ¤ì˜ API í‚¤ì—ì„œ ì‘ë™ì´ í™•ì¸ëœ ëª¨ë¸ ê³ ì •
    url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?key={GOOGLE_API_KEY}"
    
    prompt = f"""Analyze this news for stock market impact. 
    Persona: Cold-blooded expert. Output MUST be in KOREAN.
    News: {article.get('title')}
    JSON format with keys: title, summary, score, related_stocks"""

    data = {
        "contents": [{"parts": [{"text": prompt}]}],
        "safetySettings": [{"category": c, "threshold": "BLOCK_NONE"} for c in [
            "HARM_CATEGORY_DANGEROUS_CONTENT", "HARM_CATEGORY_HARASSMENT", 
            "HARM_CATEGORY_HATE_SPEECH", "HARM_CATEGORY_SEXUALLY_EXPLICIT"
        ]],
        "generationConfig": {"temperature": 0.2}
    }

    try:
        response = requests.post(url, json=data, timeout=30)
        if response.status_code == 200:
            res = response.json()
            if 'candidates' in res and res['candidates'][0].get('content'):
                text = res['candidates'][0]['content']['parts'][0]['text']
                result = json.loads(re.sub(r'```json|```', '', text).strip())
                result['engine'] = 'Gemini_Pro'
                return result
    except: pass
    return None

# ==========================================
# 3. ììœ¨ ê´€ë¦¬ ì‹œìŠ¤í…œ (Orchestrator)
# ==========================================
def start_orchestration():
    if not os.path.exists(INPUT_FILE): return
    with open(INPUT_FILE, 'r', encoding='utf-8') as f:
        articles = json.load(f).get('articles', [])

    if not articles:
        send_telegram_msg(f"ğŸ“­ [#{RUN_NUMBER}] ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    final_results = []
    # ìµœì‹  ë‰´ìŠ¤ 20ê°œë¥¼ ììœ¨ ë¶„ì„ ëŒ€ìƒìœ¼ë¡œ ì„ ì •
    target_news = articles[:20] 

    for i, art in enumerate(target_news):
        print(f"[{i+1}/{len(target_news)}] '{art.get('title')[:15]}...' ììœ¨ ë¶„ì„")
        
        # 1. Gemini Pro ì‹œë„
        res = call_gemini_smart(art)
        
        # 2. ì‹¤íŒ¨/ê±°ë¶€ ì‹œ ì¦‰ì‹œ Qwen íˆ¬ì… (ììœ¨ ì „í™˜)
        if not res:
            print("   âš ï¸ Gemini ê±°ë¶€ ê°ì§€ -> Qwen êµ¬ì¡°ëŒ€ ììœ¨ íˆ¬ì…")
            res = call_qwen_rescue(art)
            
        # 3. ìµœí›„ì˜ ë³´ë£¨ (ë°ì´í„° ë³´ì¡´)
        if not res:
            res = {"title": art.get('title'), "summary": "ë¶„ì„ ë¶ˆê°€(ìˆ˜ë™ í™•ì¸ ìš”ë§)", "score": 5.0, "stocks": [], "engine": "Fallback"}
        
        final_results.append(res)
        time.sleep(35) # ê³¼ì† ë°©ì§€ (1ë¶„ 2íšŒ ì¿¼í„° ì¤€ìˆ˜)

    # ê²°ê³¼ ì €ì¥ ë° í…”ë ˆê·¸ë¨ ë°œì†¡
    output = {"analyzed_at": str(datetime.now()), "reports": final_results}
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        json.dump(output, f, ensure_ascii=False, indent=4)

    msg = f"ğŸš€ **[GlobalStockNow #{RUN_NUMBER}] ììœ¨ ë¶„ì„ ì™„ë£Œ**\n"
    # ì ìˆ˜ ë†’ì€ ìˆœìœ¼ë¡œ ìƒìœ„ 5ê°œ ë¦¬í¬íŒ…
    for item in sorted(final_results, key=lambda x: x.get('score', 0), reverse=True)[:5]:
        icon = "ğŸ’" if item.get('engine') == 'Gemini_Pro' else "âš”ï¸"
        msg += f"\n{icon} **{item.get('title')}** ({item.get('score')}ì )\nâ”” {item.get('summary')}\n"
    
    send_telegram_msg(msg)

if __name__ == "__main__":
    start_orchestration()
