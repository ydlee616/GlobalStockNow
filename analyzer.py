import json
import time
import requests
import os
import re
import torch
from datetime import datetime
from transformers import AutoModelForCausalLM, AutoTokenizer

# ==========================================
# [ì„¤ì • ë° ììœ¨ ëª¨ë“œ ë³€ìˆ˜]
# ==========================================
GOOGLE_API_KEY = os.environ.get("GOOGLE_API_KEY")
TELEGRAM_BOT_TOKEN = os.environ.get("TELEGRAM_BOT_TOKEN")
TELEGRAM_CHAT_ID = os.environ.get("TELEGRAM_CHAT_ID")
RUN_NUMBER = os.environ.get("GITHUB_RUN_NUMBER", "Local")

INPUT_FILE = 'breaking_news.json'
OUTPUT_FILE = 'analyzed_news.json'

def send_telegram_with_button(message, article_id):
    """ë³´ìŠ¤ì˜ ì„ íƒì„ ìœ„í•œ ë²„íŠ¼ì´ í¬í•¨ëœ í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ ë°œì†¡"""
    if not TELEGRAM_BOT_TOKEN or not TELEGRAM_CHAT_ID: return
    
    url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage"
    
    # [ğŸ¬ ìœ íŠœë¸Œ ì‹œë‚˜ë¦¬ì˜¤ ìƒì„±] ë²„íŠ¼ ì¶”ê°€
    # ì‹¤ì œ êµ¬í˜„ ì‹œ ë²„íŠ¼ í´ë¦­ì„ ìˆ˜ì‹ í•  ì„œë²„ URLì´ë‚˜ GitHub Dispatchë¥¼ ì—°ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    inline_keyboard = {
        "inline_keyboard": [[
            {
                "text": "ğŸ¬ ì´ ë‰´ìŠ¤ë¡œ ìœ íŠœë¸Œ ì‹œë‚˜ë¦¬ì˜¤ ìƒì„±",
                "callback_data": f"create_video_{article_id}"
            }
        ]]
    }
    
    payload = {
        "chat_id": TELEGRAM_CHAT_ID,
        "text": message,
        "parse_mode": "Markdown",
        "reply_markup": json.dumps(inline_keyboard)
    }
    
    try:
        requests.post(url, data=payload, timeout=10)
    except Exception as e:
        print(f"í…”ë ˆê·¸ë¨ ë°œì†¡ ì˜¤ë¥˜: {e}")

# ==========================================
# 1. AI ë¶„ì„ ì—”ì§„ (8ë‹¨ê³„ ì´ˆì •ë°€ ë¶„ì„ í”„ë¡¬í”„íŠ¸ ì ìš©)
# ==========================================
print("ğŸ“‚ ë¡œì»¬ ìˆ˜ìƒ‰ëŒ€(Qwen2.5-0.5B) ìƒì‹œ ëŒ€ê¸° ì¤‘...")
tokenizer = AutoTokenizer.from_pretrained("Qwen/Qwen2.5-0.5B-Instruct")
model = AutoModelForCausalLM.from_pretrained("Qwen/Qwen2.5-0.5B-Instruct", torch_dtype="auto", device_map="cpu")

def call_strategic_ai(article):
    # ë³´ê°•ëœ 8ë‹¨ê³„ ì •ë°€ ë¶„ì„ í”„ë¡¬í”„íŠ¸ [cite: 2026-01-09]
    prompt = f"""ë‹¹ì‹ ì€ ê¸€ë¡œë²Œ ë§¤í¬ë¡œ ë¶„ì„ê°€ì´ì í•œêµ­ ì£¼ì‹ì‹œì¥ í—¤ì§€í€ë“œ ë¦¬ì„œì¹˜ ë””ë ‰í„°ì…ë‹ˆë‹¤. 
ë‹¤ìŒ í•´ì™¸ ë‰´ìŠ¤ë¥¼ ë°”íƒ•ìœ¼ë¡œ 8ë‹¨ê³„ ì •ë°€ ë¶„ì„ì„ ìˆ˜í–‰í•˜ì—¬ JSONìœ¼ë¡œ ì¶œë ¥í•˜ì‹­ì‹œì˜¤.

[ë¶„ì„ ì§€ì¹¨]:
1. ë‰´ìŠ¤ì˜ ë³¸ì§ˆ/ë°°ê²½: í•µì‹¬ ìš”ì•½ ë° í–‰ê°„ì˜ ì˜ë„(Subtext)
2. ì§ì ‘ì  ì˜í–¥: ê´€ë ¨ ê¸°ì—… ë° êµ­ê°€ ì¦ì‹œ íƒ€ê²©/ìˆ˜í˜œ
3. ê°„ì ‘ì  ì˜í–¥: í™˜ìœ¨(ì›/ë‹¬ëŸ¬), ì›ìì¬(ì„ìœ /ê¸ˆ), ê¸€ë¡œë²Œ ê³µê¸‰ë§ ë° ì§€ì •í•™ ë¦¬ìŠ¤í¬
4. íˆ¬ìì ì‹¬ë¦¬: ê¸°ëŒ€ì™€ ìš°ë ¤ ì‚¬í•­, ë³€ë™ì„± í™•ëŒ€ ê°€ëŠ¥ì„±
5. ê³¼ê±° ìœ ì‚¬ ì‚¬ë¡€ ë¹„êµ: ê³¼ê±°ì˜ ë¹„ìŠ·í•œ ì‚¬ê±´ ì†Œí™˜ ë° í˜„ì¬ì™€ì˜ ì°¨ì´ì  ë¶„ì„
6. ì‹œê°„ì¶•ë³„ ì˜í–¥: ë‹¨ê¸°(1-5ì¼), ì¤‘ê¸°(1-3ì›”), ì¥ê¸°(6ì›” ì´ìƒ) ì „ë§
7. ì—…ì¢…/ì¢…ëª© í›„ë³´: ìˆ˜í˜œ/ë¦¬ìŠ¤í¬ ì—…ì¢… TOP 3 ë° ë³€ë™ì„± ë…¸ì¶œ ì¢…ëª©
8. íˆ¬ì ì „ëµ: ê¸ì •/ë¶€ì • ì‹œë‚˜ë¦¬ì˜¤ ë° íˆ¬ìì ìœ í˜•ë³„ ì¡°ì–¸

[ì¶œë ¥ JSON êµ¬ì¡°]:
{{
  "title": "ì œëª©", "essence": {{ "subtext": "", "type": "" }},
  "direct": "", "indirect": {{ "fx": "", "commodities": "", "geopolitics": "" }},
  "sentiment": {{ "psychology": "", "volatility": "" }},
  "history": {{ "case": "", "comparison": "" }},
  "timeline": {{ "short": "", "mid": "", "long": "" }},
  "map": {{ "sectors": {{ "up": [], "down": [] }}, "stocks": [] }},
  "strategy": {{ "scenarios": "", "action": "" }},
  "score": 0.0
}}

ë‰´ìŠ¤ ì œëª©: {article.get('title')}
ë‰´ìŠ¤ ë‚´ìš©: {article.get('summary')}
"""
    # 1. Gemini Pro ì‹œë„
    try:
        url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?key={GOOGLE_API_KEY}"
        res = requests.post(url, json={"contents": [{"parts": [{"text": prompt}]}], "generationConfig": {"temperature": 0.2}}, timeout=30)
        if res.status_code == 200:
            text = res.json()['candidates'][0]['content']['parts'][0]['text']
            data = json.loads(re.sub(r'```json|```', '', text).strip())
            data['engine'] = 'Gemini_Pro'
            return data
    except: pass

    # 2. ì‹¤íŒ¨ ì‹œ Qwen Rescue ì‹œë„
    print(f"   âš”ï¸ Qwen Rescue íˆ¬ì…: {article.get('title')[:15]}...")
    inputs = tokenizer(f"<|im_start|>system\nê¸€ë¡œë²Œ ê²½ì œ ë¶„ì„ê°€ë¡œì„œ JSON í•œê¸€ ë¶„ì„ì„ ìˆ˜í–‰í•˜ì„¸ìš”.<|im_end|>\n<|im_start|>user\n{article.get('title')}<|im_end|>\n<|im_start|>assistant\n", return_tensors="pt")
    outputs = model.generate(**inputs, max_new_tokens=512)
    try:
        text = tokenizer.decode(outputs[0], skip_special_tokens=True).split("assistant")[-1]
        data = json.loads(re.search(r'\{.*\}', text, re.DOTALL).group())
        data['engine'] = 'Qwen_Rescue'
        return data
    except: return None

# ==========================================
# 3. ììœ¨ ì‹¤í–‰ ë° ë¦¬í¬íŠ¸ ìƒì„±
# ==========================================
def orchestrate():
    if not os.path.exists(INPUT_FILE): return
    with open(INPUT_FILE, 'r', encoding='utf-8') as f:
        articles = json.load(f).get('articles', [])

    if not articles:
        return

    results = []
    # ì „ëµ í‚¤ì›Œë“œ ì¤‘ì‹¬ ìƒìœ„ 10ê±´ ë¶„ì„
    for i, art in enumerate(articles[:10]):
        res = call_strategic_ai(art)
        if res:
            res['original_source'] = art.get('source')
            results.append(res)
            
            # í…”ë ˆê·¸ë¨ìœ¼ë¡œ ì¦‰ì‹œ ê°œë³„ ë³´ê³  (5ë‹¨ê³„ ë³´ê°• ì–‘ì‹)
            icon = "ğŸ’" if res.get('engine') == 'Gemini_Pro' else "âš”ï¸"
            msg = f"{icon} **1. ì œëª©: {res.get('title')}**\n"
            msg += f"**2. ë§¤ì²´**: {res.get('original_source')}\n"
            msg += f"**3. ì˜í–¥ë„ ({res.get('score')}ì )**: {res['essence'].get('subtext', 'í–‰ê°„ ë¶„ì„ì¤‘')}\n"
            msg += f"   - **ê°„ì ‘ì˜í–¥**: í™˜ìœ¨({res['indirect'].get('fx')}), ì›ìì¬({res['indirect'].get('commodities')})\n"
            msg += f"**4. ì˜í–¥ë°›ëŠ” ì£¼ì‹**: {', '.join(res['map'].get('stocks', []))}\n"
            msg += f"**5. ê³¼ê±°ì‚¬ë¡€**: {res['history'].get('case')}\n"
            msg += f"\n**ğŸ’¡ ë¶„ì„ê°€ ì œì–¸**: {res['strategy'].get('action')}"
            
            send_telegram_with_button(msg, i)
        
        time.sleep(35) # ê³¼ì† ë°©ì§€

if __name__ == "__main__":
    orchestrate()
