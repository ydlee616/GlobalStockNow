import json
import time
import requests
import os
import re
import torch
from datetime import datetime
from transformers import AutoModelForCausalLM, AutoTokenizer

# ==========================================
# [ì„¤ì • ë° ììœ¨ ëª¨ë“œ ë³€ìˆ˜]
# ==========================================
GOOGLE_API_KEY = os.environ.get("GOOGLE_API_KEY")
TELEGRAM_BOT_TOKEN = os.environ.get("TELEGRAM_BOT_TOKEN")
TELEGRAM_CHAT_ID = os.environ.get("TELEGRAM_CHAT_ID")
RUN_NUMBER = os.environ.get("GITHUB_RUN_NUMBER", "Local")

INPUT_FILE = 'breaking_news.json'
OUTPUT_FILE = 'analyzed_news.json'

def send_telegram_msg(message):
    if not TELEGRAM_BOT_TOKEN or not TELEGRAM_CHAT_ID: return
    try:
        url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage"
        payload = {"chat_id": TELEGRAM_CHAT_ID, "text": message, "parse_mode": "Markdown"}
        requests.post(url, data=payload, timeout=10)
    except: pass

# ==========================================
# 1. Rescue Engine (Qwen) - 5ë‹¨ê³„ ì–‘ì‹ í•™ìŠµ
# ==========================================
print("ğŸ“‚ ë¡œì»¬ ìˆ˜ìƒ‰ëŒ€(Qwen2.5-0.5B) ìƒì‹œ ëŒ€ê¸° ì¤‘...")
MODEL_NAME = "Qwen/Qwen2.5-0.5B-Instruct"
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, torch_dtype="auto", device_map="cpu")

def call_qwen_rescue(article):
    print(f"   âš”ï¸ Qwen Rescue íˆ¬ì…: {article.get('title')[:15]}...")
    prompt = f"""<|im_start|>system
ê¸ˆìœµ ë¶„ì„ê°€ë¡œì„œ í•œê¸€ë¡œ ë¶„ì„í•˜ì„¸ìš”. JSON format: 
{{"title": "ì œëª©", "reason": "ì˜í–¥ì‚¬ìœ ", "stocks": "ê´€ë ¨ì£¼/ì‚°ì—…", "summary": "ìš”ì•½", "score": 0.0-10.0}}<|im_end|>
<|im_start|>user
Title: {article.get('title')}
Content: {article.get('summary')}<|im_end|>
<|im_start|>assistant
"""
    inputs = tokenizer(prompt, return_tensors="pt")
    outputs = model.generate(**inputs, max_new_tokens=300, temperature=0.1)
    try:
        text = tokenizer.decode(outputs[0], skip_special_tokens=True).split("assistant")[-1]
        data = json.loads(re.search(r'\{.*\}', text, re.DOTALL).group())
        return {**data, "source": article.get('source'), "engine": "Qwen_Rescue"}
    except: return None

# ==========================================
# 2. Main Engine (Gemini Pro) - 5ë‹¨ê³„ ì–‘ì‹ í•™ìŠµ
# ==========================================
def call_gemini_smart(article):
    if not GOOGLE_API_KEY: return None
    url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?key={GOOGLE_API_KEY}"
    
    prompt = f"""
    Analyze this news for stock market impact. Output MUST be in KOREAN.
    News: {article.get('title')} - {article.get('summary')}
    
    Return ONLY JSON with these exact keys:
    {{
        "title": "í•œê¸€ ìš”ì•½ ì œëª©",
        "reason": "ì˜í–¥ ì‚¬ìœ ",
        "stocks": "ê´€ë ¨ ì‚°ì—…êµ°, í…Œë§ˆì£¼, í•´ë‹¹ ì¢…ëª© ë¦¬ìŠ¤íŠ¸",
        "summary": "ë‰´ìŠ¤ í•µì‹¬ ìš”ì•½",
        "score": 0.0-10.0
    }}
    """
    data = {
        "contents": [{"parts": [{"text": prompt}]}],
        "safetySettings": [{"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"}],
        "generationConfig": {"temperature": 0.2}
    }

    try:
        response = requests.post(url, json=data, timeout=30)
        if response.status_code == 200:
            text = response.json()['candidates'][0]['content']['parts'][0]['text']
            result = json.loads(re.sub(r'```json|```', '', text).strip())
            result['source'] = article.get('source')
            result['engine'] = 'Gemini_Pro'
            return result
    except: pass
    return None

# ==========================================
# 3. ììœ¨ ì‹¤í–‰ ë° ë¦¬í¬íŠ¸ ìƒì„±
# ==========================================
def orchestrate():
    if not os.path.exists(INPUT_FILE): return
    with open(INPUT_FILE, 'r', encoding='utf-8') as f:
        articles = json.load(f).get('articles', [])

    if not articles:
        send_telegram_msg(f"ğŸ“­ [#{RUN_NUMBER}] ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    final_results = []
    # ì „ëµ í‚¤ì›Œë“œê°€ ë°˜ì˜ëœ ìˆ˜ì§‘ ë°ì´í„° ì¤‘ ìƒìœ„ 15ê±´ ë¶„ì„
    target_articles = articles[:15]

    for art in target_articles:
        res = call_gemini_smart(art)
        if not res:
            res = call_qwen_rescue(art)
        if res:
            final_results.append(res)
        time.sleep(35) # API ì¿¼í„° ë³´í˜¸

    # í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ êµ¬ì„± (ë³´ìŠ¤ ìš”ì²­ 1, 2, 3, 4, 5 ìˆœì„œ)
    msg = f"ğŸš€ **[GlobalStockNow #{RUN_NUMBER}] Ver 0.1.3 ë¦¬í¬íŠ¸**\n"
    for item in sorted(final_results, key=lambda x: x.get('score', 0), reverse=True)[:5]:
        engine_icon = "ğŸ’" if item.get('engine') == 'Gemini_Pro' else "âš”ï¸"
        msg += f"\n{engine_icon} **1. ì œëª©**: {item.get('title')}\n"
        msg += f"   **2. ë§¤ì²´ì •ë³´**: {item.get('source')}\n"
        msg += f"   **3. ì˜í–¥ë„ ({item.get('score')}ì )**: {item.get('reason')}\n"
        msg += f"   **4. ì˜í–¥ë°›ëŠ” ì£¼ì‹**: {item.get('stocks')}\n"
        msg += f"   **5. ë‰´ìŠ¤ìš”ì•½**: {item.get('summary')}\n"
        msg += "----------------------------\n"
    
    send_telegram_msg(msg)

if __name__ == "__main__":
    orchestrate()
