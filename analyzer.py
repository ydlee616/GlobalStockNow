import json
import time
import requests
import os
import re
import torch
from datetime import datetime
from transformers import AutoModelForCausalLM, AutoTokenizer

# ==========================================
# [ì„¤ì • ë° ììœ¨ ëª¨ë“œ ë³€ìˆ˜]
# ==========================================
GOOGLE_API_KEY = os.environ.get("GOOGLE_API_KEY")
TELEGRAM_BOT_TOKEN = os.environ.get("TELEGRAM_BOT_TOKEN")
TELEGRAM_CHAT_ID = os.environ.get("TELEGRAM_CHAT_ID")
RUN_NUMBER = os.environ.get("GITHUB_RUN_NUMBER", "Local")

INPUT_FILE = 'breaking_news.json'
OUTPUT_FILE = 'analyzed_news.json'

def send_telegram_msg(message):
    if not TELEGRAM_BOT_TOKEN or not TELEGRAM_CHAT_ID: return
    try:
        url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage"
        payload = {"chat_id": TELEGRAM_CHAT_ID, "text": message, "parse_mode": "Markdown"}
        requests.post(url, data=payload, timeout=10)
    except: pass

# ==========================================
# 1. Rescue Engine (Qwen) - 4ë‹¨ê³„ ì–‘ì‹ í•™ìŠµ
# ==========================================
print("ğŸ“‚ ë¡œì»¬ ìˆ˜ìƒ‰ëŒ€(Qwen2.5-0.5B) ìƒì‹œ ëŒ€ê¸° ì¤‘...")
MODEL_NAME = "Qwen/Qwen2.5-0.5B-Instruct"
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, torch_dtype="auto", device_map="cpu")

def call_qwen_rescue(article):
    prompt = f"""<|im_start|>system
ê¸ˆìœµ ë¶„ì„ê°€ë¡œì„œ ë‰´ìŠ¤ë¥¼ ë¶„ì„í•˜ì„¸ìš”. ë°˜ë“œì‹œ í•œê¸€ë¡œ ì¶œë ¥í•˜ì„¸ìš”.
JSON format: {{"title": "í•œê¸€ì œëª©", "reason": "ì˜í–¥ë„ ì‚¬ìœ ", "summary": "í•œê¸€ìš”ì•½", "score": 0.0-10.0}}<|im_end|>
<|im_start|>user
Title: {article.get('title')}
Summary: {article.get('summary')}<|im_end|>
<|im_start|>assistant
"""
    inputs = tokenizer(prompt, return_tensors="pt")
    outputs = model.generate(**inputs, max_new_tokens=300, temperature=0.1)
    response = tokenizer.decode(outputs[0], skip_special_tokens=True)
    try:
        json_str = response.split("assistant")[-1].strip()
        data = json.loads(re.search(r'\{.*\}', json_str, re.DOTALL).group())
        return {**data, "source": article.get('source'), "engine": "Qwen_Rescue"}
    except: return None

# ==========================================
# 2. Main Engine (Gemini Pro) - 4ë‹¨ê³„ ì–‘ì‹ í•™ìŠµ
# ==========================================
def call_gemini_smart(article):
    if not GOOGLE_API_KEY: return None
    url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?key={GOOGLE_API_KEY}"
    
    prompt = f"""
    Analyze this news for stock market impact. Output MUST be in KOREAN.
    News: {article.get('title')} - {article.get('summary')}
    
    Return ONLY JSON with these exact keys:
    {{
        "title": "í•œê¸€ ìš”ì•½ ì œëª©",
        "reason": "í•œêµ­ ì£¼ì‹ì‹œì¥ì— ë¯¸ì¹˜ëŠ” êµ¬ì²´ì  ì˜í–¥ ì‚¬ìœ ",
        "summary": "ë‰´ìŠ¤ ë‚´ìš© í•µì‹¬ ìš”ì•½",
        "score": 0.0-10.0
    }}
    """
    data = {
        "contents": [{"parts": [{"text": prompt}]}],
        "safetySettings": [{"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"}],
        "generationConfig": {"temperature": 0.2}
    }

    try:
        response = requests.post(url, json=data, timeout=30)
        if response.status_code == 200:
            text = response.json()['candidates'][0]['content']['parts'][0]['text']
            result = json.loads(re.sub(r'```json|```', '', text).strip())
            result['source'] = article.get('source')
            result['engine'] = 'Gemini_Pro'
            return result
    except: pass
    return None

# ==========================================
# 3. ììœ¨ ì‹¤í–‰ ë° ë¦¬í¬íŠ¸ ìƒì„±
# ==========================================
def orchestrate():
    if not os.path.exists(INPUT_FILE): return
    with open(INPUT_FILE, 'r', encoding='utf-8') as f:
        articles = json.load(f).get('articles', [])

    final_results = []
    target_articles = articles[:15] # ìš°ì„  ê³ í’ˆì§ˆ 15ê±´ ë¶„ì„

    for i, art in enumerate(target_articles):
        res = call_gemini_smart(art)
        if not res:
            res = call_qwen_rescue(art)
        
        if res:
            final_results.append(res)
        time.sleep(35)

    # í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ êµ¬ì„± (ë³´ìŠ¤ ìš”ì²­ 1, 2, 3, 4 ìˆœì„œ)
    msg = f"ğŸš€ **[GlobalStockNow #{RUN_NUMBER}] Ver 0.1 ë¦¬í¬íŠ¸**\n"
    for item in sorted(final_results, key=lambda x: x.get('score', 0), reverse=True)[:5]:
        engine_icon = "ğŸ’" if item.get('engine') == 'Gemini_Pro' else "âš”ï¸"
        msg += f"\n{engine_icon} **1. ì œëª©: {item.get('title')}**\n"
        msg += f"   **2. ë§¤ì²´**: {item.get('source')}\n"
        msg += f"   **3. ì˜í–¥ë„ ({item.get('score')}ì )**: {item.get('reason')}\n"
        msg += f"   **4. ìš”ì•½**: {item.get('summary')}\n"
        msg += "----------------------------\n"
    
    send_telegram_msg(msg)

if __name__ == "__main__":
    orchestrate()
