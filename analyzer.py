import json
import time
import requests
import os
import re
from datetime import datetime

# ==========================================
# [ì„¤ì • ì˜ì—­]
# ==========================================
GOOGLE_API_KEY = os.environ.get("GOOGLE_API_KEY")
TELEGRAM_BOT_TOKEN = os.environ.get("TELEGRAM_BOT_TOKEN")
TELEGRAM_CHAT_ID = os.environ.get("TELEGRAM_CHAT_ID")
RUN_NUMBER = os.environ.get("GITHUB_RUN_NUMBER", "Local")

IMPACT_THRESHOLD = 2.0
INPUT_FILE = 'breaking_news.json'
OUTPUT_FILE = 'analyzed_news.json'

def send_telegram_msg(message):
    if not TELEGRAM_BOT_TOKEN or not TELEGRAM_CHAT_ID: return
    try:
        url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage"
        payload = {"chat_id": TELEGRAM_CHAT_ID, "text": message, "parse_mode": "Markdown"}
        requests.post(url, data=payload, timeout=5)
    except: pass

# ==========================================
# 1. ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ìë™ ì°¾ê¸°
# ==========================================
def get_best_model():
    if not GOOGLE_API_KEY: return None, 0
    
    print("ğŸ” [System] Checking available models...")
    url = f"https://generativelanguage.googleapis.com/v1beta/models?key={GOOGLE_API_KEY}"
    
    try:
        response = requests.get(url, timeout=10)
        if response.status_code == 200:
            models = [m['name'] for m in response.json().get('models', [])]
            
            # ìš°ì„ ìˆœìœ„: 1.5 Flash (ë¹ ë¦„) -> 1.5 Pro (ì„±ëŠ¥) -> 1.0 Pro (í˜¸í™˜ì„±)
            for m in models:
                if 'gemini-1.5-flash' in m: return m, 5  # 5ì´ˆ íœ´ì‹
            for m in models:
                if 'gemini-1.5-pro' in m: return m, 40   # 40ì´ˆ íœ´ì‹
            for m in models:
                if 'gemini-pro' in m: return m, 40       # 40ì´ˆ íœ´ì‹
                
    except: pass
    
    # ì‹¤íŒ¨ ì‹œ ì•ˆì „í•œ ê¸°ë³¸ê°’ (gemini-pro + 40ì´ˆ)
    print("âš ï¸ [System] Model check failed. Using fallback: models/gemini-pro")
    return "models/gemini-pro", 40

SELECTED_MODEL, BATCH_DELAY = get_best_model()

# ==========================================
# 2. Gemini API í˜¸ì¶œ (í•µì‹¬ ì—”ì§„)
# ==========================================
def call_gemini(prompt):
    if not GOOGLE_API_KEY or not SELECTED_MODEL: return None

    url = f"https://generativelanguage.googleapis.com/v1beta/{SELECTED_MODEL}:generateContent?key={GOOGLE_API_KEY}"
    headers = {'Content-Type': 'application/json'}
    
    # JSON í¬ë§· ê°•ì œ + ì•ˆì „ì¥ì¹˜ í•´ì œ
    full_prompt = prompt + "\n\n[SYSTEM]: Output strictly a valid JSON list. No Markdown."
    
    data = {
        "contents": [{"parts": [{"text": full_prompt}]}],
        "safetySettings": [
            {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"}
        ],
        "generationConfig": {"temperature": 0.3}
    }

    for attempt in range(3):
        try:
            response = requests.post(url, headers=headers, json=data, timeout=60)
            
            if response.status_code == 200:
                try:
                    text = response.json()['candidates'][0]['content']['parts'][0]['text']
                    clean_text = re.sub(r'```json|```', '', text).strip()
                    # ìœ íš¨ì„± ê²€ì‚¬
                    json.loads(clean_text)
                    return clean_text
                except:
                    # ë¸”ë½ë˜ì—ˆê±°ë‚˜ JSONì´ ê¹¨ì§„ ê²½ìš°
                    return None
            
            elif response.status_code == 429:
                print(f"â³ Rate Limit (429). Waiting {BATCH_DELAY+10}s...")
                time.sleep(BATCH_DELAY + 10)
                continue
            else:
                print(f"âŒ API Error {response.status_code}")
                return None

        except Exception as e:
            print(f"âŒ Connection Error: {e}")
            time.sleep(5)
            continue
            
    return None

# ==========================================
# 3. ìŠ¤ë§ˆíŠ¸ ë¶„í•  ë¶„ì„ (Adaptive Batching)
# ==========================================
def analyze_smartly(articles):
    results = []
    # ê¸°ë³¸ ë°°ì¹˜ ì‚¬ì´ì¦ˆ 5
    batch_size = 5
    
    print(f"ğŸ”„ [Run #{RUN_NUMBER}] Analysis Started (Model: {SELECTED_MODEL})...")
    print(f"   Target: {len(articles)} articles. Strategy: Batch -> Individual Fallback")

    i = 0
    while i < len(articles):
        batch = articles[i : i + batch_size]
        print(f"   Processing Batch {i//batch_size + 1} ({len(batch)} items)...")
        
        prompt = f"""
        Analyze these news articles.
        [Articles]: {json.dumps(batch, ensure_ascii=False)}
        [Requirement]: Return a JSON LIST of objects: title, summary, score, related_stocks.
        """
        
        # 1ì°¨ ì‹œë„: ë¬¶ìŒ ì²˜ë¦¬
        response = call_gemini(prompt)
        success = False
        
        if response:
            try:
                data = json.loads(response)
                if isinstance(data, list) and len(data) > 0:
                    results.extend(data)
                    success = True
                    print(f"   âœ… Batch Success! (+{len(data)} items)")
            except: pass
        
        # 2ì°¨ ì‹œë„: ì‹¤íŒ¨ ì‹œ ë‚±ê°œ ì²˜ë¦¬ (Rescue Mode)
        if not success:
            print("   âš ï¸ Batch Failed/Blocked. Switching to Rescue Mode (1-by-1)...")
            for article in batch:
                print(f"      Running Rescue for: {article.get('title')[:20]}...")
                single_prompt = f"""
                Analyze this ONE news article.
                [Article]: {json.dumps([article], ensure_ascii=False)}
                [Requirement]: Return a JSON LIST of objects: title, summary, score, related_stocks.
                """
                res = call_gemini(single_prompt)
                if res:
                    try:
                        d = json.loads(res)
                        if isinstance(d, list): results.extend(d)
                        elif isinstance(d, dict): results.append(d)
                        print("      âœ… Rescued!")
                    except: print("      âŒ Failed.")
                
                # ë‚±ê°œ ì²˜ë¦¬ ì‹œì—ë„ ì§§ì€ íœ´ì‹
                time.sleep(5) 

        # ë‹¤ìŒ ë°°ì¹˜ë¡œ ë„˜ì–´ê°€ê¸° ì „ íœ´ì‹
        print(f"   â˜• Resting {BATCH_DELAY}s...")
        time.sleep(BATCH_DELAY)
        i += batch_size

    return results

# ==========================================
# 4. ì €ì¥ ë° ì•Œë¦¼
# ==========================================
def save_and_notify(data):
    # ë¹ˆ ê²°ê³¼ë¼ë„ ì €ì¥ (íŒŒì¼ ë®ì–´ì“°ê¸° ë°©ì§€)
    output_data = {
        "analyzed_at": str(datetime.now()),
        "run_number": RUN_NUMBER,
        "count": len(data),
        "reports": data
    }
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, ensure_ascii=False, indent=4)
    
    print(f"âœ… Final Count: {len(data)} reports saved.")

    if not TELEGRAM_BOT_TOKEN: return

    if not data:
        send_telegram_msg(f"ğŸš« [GlobalStockNow #{RUN_NUMBER}] ë¶„ì„ ì‹¤íŒ¨. (ëª¨ë“  ë‰´ìŠ¤ê°€ ê±°ë¶€ë¨)")
        return

    top_news = [r for r in data if float(r.get('score', 0)) >= IMPACT_THRESHOLD]
    top_news.sort(key=lambda x: x.get('score', 0), reverse=True)
    top_news = top_news[:5]

    msg = f"ğŸš€ **[GlobalStockNow ì†ë³´ (#{RUN_NUMBER})]**\n(ë¶„ì„ ì„±ê³µ: {len(data)}ê±´)\n\n"
    
    if not top_news:
        msg += "íŠ¹ì´ì‚¬í•­ ì—†ìŒ (ì¤‘ìš” ë‰´ìŠ¤ ì—†ìŒ)"
    else:
        for item in top_news:
            score = item.get('score', 0)
            icon = "ğŸ”¥" if score >= 7.0 else "âš¡"
            msg += f"{icon} **{item.get('title')}** ({score}ì )\n"
            msg += f"â”” {item.get('summary')}\n"
            msg += f"â”” ê´€ë ¨ì£¼: {', '.join(item.get('related_stocks', []))}\n\n"
    
    send_telegram_msg(msg)

if __name__ == "__main__":
    if os.path.exists(INPUT_FILE):
        with open(INPUT_FILE, 'r', encoding='utf-8') as f:
            raw_data = json.load(f)
            if isinstance(raw_data, list): articles = raw_data
            else: articles = raw_data.get('articles', [])
            
        if articles:
            results = analyze_smartly(articles)
            save_and_notify(results)
        else:
            print("ğŸ“­ ë‰´ìŠ¤ ë°ì´í„° ì—†ìŒ")
    else:
        print(f"âŒ {INPUT_FILE} íŒŒì¼ ì—†ìŒ")
