import json
import time
import requests
import os
import re
from datetime import datetime

# ==========================================
# [ì„¤ì • ì˜ì—­]
# ==========================================
GOOGLE_API_KEY = os.environ.get("GOOGLE_API_KEY")
TELEGRAM_BOT_TOKEN = os.environ.get("TELEGRAM_BOT_TOKEN")
TELEGRAM_CHAT_ID = os.environ.get("TELEGRAM_CHAT_ID")
RUN_NUMBER = os.environ.get("GITHUB_RUN_NUMBER", "Local")

IMPACT_THRESHOLD = 2.0
INPUT_FILE = 'breaking_news.json'
OUTPUT_FILE = 'analyzed_news.json'

def send_telegram_msg(message):
    if not TELEGRAM_BOT_TOKEN or not TELEGRAM_CHAT_ID: return
    try:
        url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage"
        payload = {"chat_id": TELEGRAM_CHAT_ID, "text": message, "parse_mode": "Markdown"}
        requests.post(url, data=payload, timeout=5)
    except: pass

# ==========================================
# 1. ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ë° ì†ë„ ìë™ ê°ì§€ (í•µì‹¬)
# ==========================================
def get_optimal_model_and_delay():
    if not GOOGLE_API_KEY: return None, 0

    print("ğŸ” Checking available AI models for your API Key...")
    url = f"https://generativelanguage.googleapis.com/v1beta/models?key={GOOGLE_API_KEY}"
    
    try:
        response = requests.get(url, timeout=10)
        if response.status_code == 200:
            data = response.json()
            models = [m['name'] for m in data.get('models', [])]
            
            # 1ìˆœìœ„: Gemini 1.5 Flash (ë¹ ë¦„, 5ì´ˆ íœ´ì‹)
            for m in models:
                if 'gemini-1.5-flash' in m:
                    print(f"âœ… Found Fast Model: {m}")
                    return m, 5
            
            # 2ìˆœìœ„: Gemini 1.5 Pro (ëŠë¦¼, 35ì´ˆ íœ´ì‹)
            for m in models:
                if 'gemini-1.5-pro' in m:
                    print(f"âœ… Found High-Performance Model: {m}")
                    return m, 35
            
            # 3ìˆœìœ„: Gemini Pro Legacy (ëŠë¦¼, 35ì´ˆ íœ´ì‹)
            for m in models:
                if 'gemini-pro' in m:
                    print(f"âœ… Found Legacy Model: {m}")
                    return m, 35
                    
        print("âš ï¸ Model list check failed. Fallback to 'gemini-pro'.")
    except Exception as e:
        print(f"âš ï¸ Connection error during model check: {e}")

    # ì•ˆì „í•˜ê²Œ ê¸°ë³¸ê°’ì€ Pro + 35ì´ˆ (404 ë°©ì§€ë³´ë‹¤ëŠ” 429 ë°©ì§€ê°€ ë‚˜ìŒ)
    return "models/gemini-pro", 35

# ëª¨ë¸ê³¼ ë”œë ˆì´ í™•ì •
SELECTED_MODEL, BATCH_DELAY = get_optimal_model_and_delay()

# ==========================================
# 2. Gemini API í˜¸ì¶œ
# ==========================================
def call_gemini(prompt):
    if not GOOGLE_API_KEY or not SELECTED_MODEL: return None

    url = f"https://generativelanguage.googleapis.com/v1beta/{SELECTED_MODEL}:generateContent?key={GOOGLE_API_KEY}"
    headers = {'Content-Type': 'application/json'}
    
    # JSON ê°•ì œ ì¶œë ¥ í”„ë¡¬í”„íŠ¸
    full_prompt = prompt + "\n\n[SYSTEM]: Output strictly a valid JSON list. No Markdown, no explanation."

    data = {
        "contents": [{"parts": [{"text": full_prompt}]}],
        # ì•ˆì „ì¥ì¹˜ í•´ì œ (ë‰´ìŠ¤ ë¶„ì„ ê±°ë¶€ ë°©ì§€)
        "safetySettings": [
            {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"}
        ],
        "generationConfig": {"temperature": 0.3}
    }

    # ì¬ì‹œë„ ë¡œì§
    for attempt in range(3):
        try:
            response = requests.post(url, headers=headers, json=data, timeout=30)
            
            if response.status_code == 200:
                text = response.json()['candidates'][0]['content']['parts'][0]['text']
                # ë§ˆí¬ë‹¤ìš´ ì½”ë“œë¸”ë¡ ì œê±°
                clean_text = re.sub(r'```json|```', '', text).strip()
                return clean_text
            
            elif response.status_code == 429:
                print(f"â³ Quota Exceeded (429). Cooling down {BATCH_DELAY + 10}s... ({attempt+1}/3)")
                time.sleep(BATCH_DELAY + 10) # ì§€ì •ëœ ë”œë ˆì´ë³´ë‹¤ ì¡°ê¸ˆ ë” ì‰¼
                continue
            
            elif response.status_code == 404:
                print(f"âŒ Critical Error: Model {SELECTED_MODEL} not found (404).")
                return None
            
            else:
                print(f"âŒ API Error {response.status_code}: {response.text[:100]}")
                time.sleep(5)
                continue

        except Exception as e:
            print(f"âŒ Connection Error: {e}")
            time.sleep(5)
            continue
            
    return None

# ==========================================
# 3. ë‰´ìŠ¤ ë¶„ì„ (ë°°ì¹˜ ì²˜ë¦¬)
# ==========================================
def analyze_news_batch(articles):
    results = []
    # í•œ ë²ˆì— 4ê°œì”© ì²˜ë¦¬
    batch_size = 4
    
    print(f"ğŸ”„ [Run #{RUN_NUMBER}] Analysis Started using {SELECTED_MODEL} (Delay: {BATCH_DELAY}s)...")

    # ìµœëŒ€ 34ê°œ ë‰´ìŠ¤ ì²˜ë¦¬
    for i in range(0, len(articles), batch_size):
        batch = articles[i:i + batch_size]
        print(f"   Processing batch {i//batch_size + 1}/{len(articles)//batch_size + 1}...")
        
        prompt = f"""
        Analyze the following financial news articles.
        
        [Articles]:
        {json.dumps(batch, ensure_ascii=False)}

        [Requirement]:
        Return a JSON LIST of objects with these exact keys:
        - title (Korean summary)
        - summary (Korean 1 sentence)
        - score (Float 0.0-10.0 impact score)
        - related_stocks (List of strings)
        """

        response_text = call_gemini(prompt)
        
        if response_text:
            try:
                data = json.loads(response_text)
                if isinstance(data, list): results.extend(data)
                elif isinstance(data, dict): 
                    if 'articles' in data: results.extend(data['articles'])
                    else: results.append(data)
            except: 
                print("âš ï¸ JSON Parsing Failed for this batch.")
        
        # ğŸ”¥ ë™ì ìœ¼ë¡œ ì„¤ì •ëœ ë”œë ˆì´ë§Œí¼ íœ´ì‹
        print(f"   â˜• Resting {BATCH_DELAY}s...")
        time.sleep(BATCH_DELAY)

    return results

# ==========================================
# 4. ì €ì¥ ë° ì•Œë¦¼
# ==========================================
def save_and_notify(data):
    # ê²°ê³¼ ì €ì¥
    output_data = {
        "analyzed_at": str(datetime.now()),
        "run_number": RUN_NUMBER,
        "count": len(data),
        "reports": data
    }
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, ensure_ascii=False, indent=4)
    
    print(f"âœ… Analysis Complete! Total {len(data)} reports saved.")

    if not TELEGRAM_BOT_TOKEN: return

    if not data:
        send_telegram_msg(f"ğŸš« [GlobalStockNow #{RUN_NUMBER}] ë¶„ì„ ì‹¤íŒ¨: ê²°ê³¼ ë°ì´í„° ì—†ìŒ ({SELECTED_MODEL})")
        return

    # ì¤‘ìš” ë‰´ìŠ¤ í•„í„°ë§
    top_news = [r for r in data if float(r.get('score', 0)) >= IMPACT_THRESHOLD]
    top_news.sort(key=lambda x: x.get('score', 0), reverse=True)
    top_news = top_news[:5] # ìƒìœ„ 5ê°œë§Œ ì „ì†¡

    msg = f"ğŸš€ **[GlobalStockNow ì†ë³´ (#{RUN_NUMBER})]**\n(ëª¨ë¸: {SELECTED_MODEL})\n\n"
    
    if not top_news:
        msg += "íŠ¹ì´ì‚¬í•­ ì—†ìŒ (ì¤‘ìš” ë‰´ìŠ¤ ì—†ìŒ)"
    else:
        for item in top_news:
            score = item.get('score', 0)
            icon = "ğŸ”¥" if score >= 7.0 else "âš¡"
            msg += f"{icon} **{item.get('title')}** ({score}ì )\n"
            msg += f"â”” {item.get('summary')}\n"
            msg += f"â”” ê´€ë ¨ì£¼: {', '.join(item.get('related_stocks', []))}\n\n"
    
    send_telegram_msg(msg)

if __name__ == "__main__":
    if os.path.exists(INPUT_FILE):
        with open(INPUT_FILE, 'r', encoding='utf-8') as f:
            raw_data = json.load(f)
            # JSON êµ¬ì¡° í˜¸í™˜ì„± ì²˜ë¦¬
            if isinstance(raw_data, list): articles = raw_data
            else: articles = raw_data.get('articles', [])
            
        if articles:
            results = analyze_news_batch(articles)
            save_and_notify(results)
        else:
            print("ğŸ“­ No news data found.")
            # ë°ì´í„°ê°€ ì—†ì„ ë•ŒëŠ” ì¡°ìš©íˆ ì¢…ë£Œ (ì´ì „ ë‹¨ê³„ì—ì„œ ìˆ˜ì§‘ ì‹¤íŒ¨ ì•Œë¦¼ì´ ê°”ì„ ê²ƒì„)
    else:
        print(f"âŒ Input file {INPUT_FILE} not found.")
