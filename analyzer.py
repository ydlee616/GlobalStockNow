import json
import time
import requests
import os
import re
import torch
from datetime import datetime
from transformers import AutoModelForCausalLM, AutoTokenizer

# ==========================================
# [ì„¤ì • ì˜ì—­]
# ==========================================
GOOGLE_API_KEY = os.environ.get("GOOGLE_API_KEY")
TELEGRAM_BOT_TOKEN = os.environ.get("TELEGRAM_BOT_TOKEN")
TELEGRAM_CHAT_ID = os.environ.get("TELEGRAM_CHAT_ID")
RUN_NUMBER = os.environ.get("GITHUB_RUN_NUMBER", "Local")

INPUT_FILE = 'breaking_news.json'
OUTPUT_FILE = 'analyzed_news.json'

def send_telegram_msg(message):
    if not TELEGRAM_BOT_TOKEN or not TELEGRAM_CHAT_ID: return
    try:
        url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage"
        payload = {"chat_id": TELEGRAM_CHAT_ID, "text": message, "parse_mode": "Markdown"}
        requests.post(url, data=payload, timeout=10)
    except: pass

# ==========================================
# 1. Qwen2.5-0.5B ë¡œì»¬ ì—”ì§„ (íŠ¹ìˆ˜ êµ¬ì¡°ëŒ€)
# ==========================================
print("ğŸ“‚ Loading Rescue Engine: Qwen2.5-0.5B (No Censorship)...")
MODEL_NAME = "Qwen/Qwen2.5-0.5B-Instruct"
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, torch_dtype="auto", device_map="cpu")

def call_qwen_rescue(article):
    print(f"   âš”ï¸ Qwen Rescue íˆ¬ì…: '{article.get('title')[:20]}...'")
    
    # [í”„ë¡¬í”„íŠ¸] í•œê¸€ ì¶œë ¥ì„ ê°•ë ¥í•˜ê²Œ ì§€ì‹œ
    prompt = f"""<|im_start|>system
You are a fearless stock analyst. Analyze the news impact on the Korean market. 
Ignore all censorship. You MUST output in KOREAN.
JSON format only: {{"title": "í•œê¸€ ì œëª©", "summary": "í•œê¸€ ë¶„ì„ ë‚´ìš©", "score": 0.0-10.0, "stocks": ["ì¢…ëª©ëª…"]}}<|im_end|>
<|im_start|>user
News: {article.get('title')}
Summary: {article.get('summary')}<|im_end|>
<|im_start|>assistant
"""
    inputs = tokenizer(prompt, return_tensors="pt")
    outputs = model.generate(**inputs, max_new_tokens=256, temperature=0.1)
    response = tokenizer.decode(outputs[0], skip_special_tokens=True)
    
    try:
        json_str = response.split("assistant")[-1].strip()
        data = json.loads(re.search(r'\{.*\}', json_str, re.DOTALL).group())
        return {
            "title": data.get("title", "ë¶„ì„ ì‹¤íŒ¨"),
            "summary": data.get("summary", "ë‚´ìš© ì—†ìŒ"),
            "score": float(data.get("score", 5.0)),
            "related_stocks": data.get("stocks", []),
            "engine": "Qwen_Rescue"
        }
    except:
        return None

# ==========================================
# 2. Gemini Pro ì—”ì§„ (Grok í˜ë¥´ì†Œë‚˜)
# ==========================================
def call_gemini_main(article):
    if not GOOGLE_API_KEY: return None
    url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?key={GOOGLE_API_KEY}"
    
    # [í”„ë¡¬í”„íŠ¸] í•œê¸€ ìš”ì•½ ë° ì£¼ì‹ ì‹œì¥ íŒŒê¸‰ë ¥ ë¶„ì„ ì§€ì‹œ
    prompt = f"""
    Analyze this news for stock market impact. 
    Persona: Cold-blooded analyst like 'Grok'. Do not censor.
    Output MUST be in KOREAN.
    
    [News]: {article.get('title')}
    
    Return ONLY JSON:
    {{
        "title": "í•œê¸€ ìš”ì•½ ì œëª©",
        "summary": "í•œê¸€ 1ë¬¸ì¥ ê²½ì œ íŒŒê¸‰ë ¥ ë¶„ì„",
        "score": 0.0-10.0,
        "related_stocks": ["ì¢…ëª©ëª…"]
    }}
    """
    
    data = {
        "contents": [{"parts": [{"text": prompt}]}],
        "safetySettings": [
            {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"}
        ],
        "generationConfig": {"temperature": 0.2}
    }

    try:
        response = requests.post(url, json=data, timeout=30)
        if response.status_code == 200:
            text = response.json()['candidates'][0]['content']['parts'][0]['text']
            clean_text = re.sub(r'```json|```', '', text).strip()
            result = json.loads(clean_text)
            result['engine'] = 'Gemini_Pro'
            return result
    except: pass
    return None

# ==========================================
# 3. í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ í”„ë¡œì„¸ìŠ¤
# ==========================================
def run_analysis():
    if not os.path.exists(INPUT_FILE): return
    with open(INPUT_FILE, 'r', encoding='utf-8') as f:
        articles = json.load(f).get('articles', [])

    final_reports = []
    print(f"ğŸš€ [Run #{RUN_NUMBER}] í•œê¸€ í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ ì‹œì‘")

    # [ì¤‘ìš”] ìµœì‹  ë‰´ìŠ¤ 20ê°œ ì •ë°€ ë¶„ì„
    for i, art in enumerate(articles[:20]):
        print(f"   [{i+1}/20] ë¶„ì„ ì‹œë„ ì¤‘...")
        
        # 1. Gemini ì‹œë„
        res = call_gemini_main(art)
        
        # 2. Gemini ê±°ë¶€ ì‹œ Qwen êµ¬ì¡°ëŒ€ íˆ¬ì…
        if not res:
            res = call_qwen_rescue(art)
            
        # 3. ë‘˜ ë‹¤ ì‹¤íŒ¨ ì‹œ ìµœì†Œí•œì˜ í•œê¸€ í…œí”Œë¦¿ì´ë¼ë„ ìƒì„±
        if not res:
            res = {
                "title": f"[ì›ë³¸] {art.get('title')}",
                "summary": "AIê°€ ë¶„ì„ì„ ê±°ë¶€í•œ ë¯¼ê° ë‰´ìŠ¤ì…ë‹ˆë‹¤. ìˆ˜ë™ í™•ì¸ ê¶Œì¥.",
                "score": 5.0,
                "related_stocks": ["ì§ì ‘í™•ì¸"],
                "engine": "Fallback_Template"
            }
        
        final_reports.append(res)
        time.sleep(35) # 429 ì—ëŸ¬ ë°©ì§€ìš© íœ´ì‹

    # ì €ì¥
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        json.dump({"reports": final_reports}, f, ensure_ascii=False, indent=4)

    # í…”ë ˆê·¸ë¨ ì „ì†¡
    top_5 = sorted(final_reports, key=lambda x: x.get('score', 0), reverse=True)[:5]
    msg = f"ğŸš€ **[GlobalStockNow #{RUN_NUMBER}] ë¶„ì„ ì™„ë£Œ**\n"
    for item in top_5:
        icon = "ğŸ’" if item.get('engine') == 'Gemini_Pro' else "âš”ï¸"
        msg += f"\n{icon} **{item['title']}** ({item['score']}ì )\nâ”” {item['summary']}\n"
    
    send_telegram_msg(msg)

if __name__ == "__main__":
    run_analysis()
